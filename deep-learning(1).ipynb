{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport gc\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers\n\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import fbeta_score","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes = pd.read_csv('/kaggle/input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the train labels\nlabels = train_classes['tags'].apply(lambda x: x.split(' '))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting a dictionary of unique labels\nfrom collections import Counter\nlabels_count = Counter(label for lbs in labels for label in lbs)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_list = list(labels_count.keys())\ntag_values = list(labels_count.values())","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tag_list)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"17"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_classes = pd.read_csv('/kaggle/input/planets-dataset/planet/planet/sample_submission.csv')\ntest_classes.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"  image_name                                  tags\n0     test_0  primary clear agriculture road water\n1     test_1  primary clear agriculture road water\n2     test_2  primary clear agriculture road water\n3     test_3  primary clear agriculture road water\n4     test_4  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the test labels\nlabels = train_classes['tags'].apply(lambda x: x.split(' '))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting a dictionary for the test labels\nlabels_count = Counter(label for lbs in labels for label in lbs)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tag_list = list(labels_count.keys())\ntest_tag_values = list(labels_count.values())","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_tag_list)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"17"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map = {i:j for j, i in enumerate(tag_list)}\nlabel_map","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"{'haze': 0,\n 'primary': 1,\n 'agriculture': 2,\n 'clear': 3,\n 'water': 4,\n 'habitation': 5,\n 'road': 6,\n 'cultivation': 7,\n 'slash_burn': 8,\n 'cloudy': 9,\n 'partly_cloudy': 10,\n 'conventional_mine': 11,\n 'bare_ground': 12,\n 'artisinal_mine': 13,\n 'blooming': 14,\n 'selective_logging': 15,\n 'blow_down': 16}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, Y_train = [], []\nfor img, label in tqdm(train_classes.values, miniters = 1000):\n    target = np.zeros(17)\n    for tag in label.split(' '):\n        target[label_map[tag]]=1\n    Y_train.append(target)","execution_count":15,"outputs":[{"output_type":"stream","text":"100%|██████████| 40479/40479 [00:00<00:00, 181863.71it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gets all the jpg paths for the train-jpg file\nimport glob\ntrain_images_path = glob.glob('/kaggle/input/planets-dataset/planet/planet/train-jpg/*.jpg')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfor file in train_images_path:\n     X_train.append(cv2.resize(cv2.imread(file), (64,64)))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.getsizeof(X_train)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"361296"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#changing the data type to an array and also scaling\nx_train = np.array(X_train, np.float16)/255\ny_train = np.array(Y_train, np.uint8)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, x_val, train_Y, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\nprint(train_X.shape, train_Y.shape, x_val.shape, y_val.shape)","execution_count":21,"outputs":[{"output_type":"stream","text":"(32383, 64, 64, 3) (32383, 17) (8096, 64, 64, 3) (8096, 17)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(X_train, Y_train)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n\n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first model using CNN\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu', input_shape=(64, 64,3)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(17, activation='sigmoid'))","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nlearn_rate = 0.0001\nopt  = optimizers.Adam(lr=learn_rate)\nmodel.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n#    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)] #save the weights of the best performing model\n\nmodel.fit(x = train_X, y= train_Y, validation_data=(x_val, y_val),batch_size=128,verbose=2, epochs=epochs)\np_val = model.predict(x_val, batch_size = 32, verbose=2)\nprint(fbeta_score(y_val, np.array(p_val) > 0.2, beta=2, average='samples')) #Check the model performance on the validation set","execution_count":29,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n253/253 - 8s - loss: 0.2578 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 2/20\n253/253 - 7s - loss: 0.2578 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 3/20\n253/253 - 7s - loss: 0.2578 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 4/20\n253/253 - 7s - loss: 0.2578 - accuracy: 0.8590 - val_loss: 0.2533 - val_accuracy: 0.8678\nEpoch 5/20\n253/253 - 7s - loss: 0.2575 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 6/20\n253/253 - 7s - loss: 0.2576 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 7/20\n253/253 - 7s - loss: 0.2575 - accuracy: 0.8590 - val_loss: 0.2533 - val_accuracy: 0.8678\nEpoch 8/20\n253/253 - 7s - loss: 0.2577 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 9/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 10/20\n253/253 - 7s - loss: 0.2575 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 11/20\n253/253 - 7s - loss: 0.2575 - accuracy: 0.8590 - val_loss: 0.2535 - val_accuracy: 0.8678\nEpoch 12/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2533 - val_accuracy: 0.8678\nEpoch 13/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 14/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2535 - val_accuracy: 0.8678\nEpoch 15/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 16/20\n253/253 - 7s - loss: 0.2574 - accuracy: 0.8590 - val_loss: 0.2540 - val_accuracy: 0.8678\nEpoch 17/20\n253/253 - 7s - loss: 0.2573 - accuracy: 0.8590 - val_loss: 0.2535 - val_accuracy: 0.8678\nEpoch 18/20\n253/253 - 7s - loss: 0.2573 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 19/20\n253/253 - 7s - loss: 0.2572 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\nEpoch 20/20\n253/253 - 7s - loss: 0.2573 - accuracy: 0.8590 - val_loss: 0.2534 - val_accuracy: 0.8678\n253/253 - 1s\n0.6776057377605501\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"119"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#second model using transfer learning \nfrom keras.applications.resnet import ResNet152\nfrom keras.layers import BatchNormalization\nbase_model = ResNet152(include_top=False, weights='imagenet', input_shape=(64, 64, 3), pooling='avg')\n#base_model.trainable = False # Freeze the base_model\n\nmodel_2 = keras.models.Sequential()\nmodel_2.add(BatchNormalization(input_shape=(64, 64, 3)))\nmodel_2.add(base_model)\nmodel_2.add(Flatten())\nmodel_2.add(Dense(512, activation = \"relu\"))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(Dense(17, activation = \"sigmoid\"))\nmodel_2.summary()","execution_count":26,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization (BatchNo (None, 64, 64, 3)         12        \n_________________________________________________________________\nresnet152 (Functional)       (None, 2048)              58370944  \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               1049088   \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 17)                8721      \n=================================================================\nTotal params: 59,428,765\nTrainable params: 59,277,335\nNon-trainable params: 151,430\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nlearning_rate = 0.0001\nlr_decay = 1e-4\nbatch_size=64\nepochs=20\nopt = Adam(lr=learning_rate, decay=lr_decay)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.compile(loss='binary_crossentropy',optimizer=opt,metrics=[fbeta])\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n#    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)] #save the weights of the best performing model\n\nmodel_2.fit(x = train_X, y= train_Y, validation_data=(x_val, y_val),batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n        \np_val = model_2.predict(x_val, batch_size = 32, verbose=2)\nprint(fbeta_score(y_val, np.array(p_val) > 0.2, beta=2, average='samples')) #Check the model performance on the validation set","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n253/253 - 58s - loss: 0.3161 - fbeta: 0.5747 - val_loss: 0.2697 - val_fbeta: 0.6110\nEpoch 2/20\n253/253 - 54s - loss: 0.2693 - fbeta: 0.5938 - val_loss: 0.2585 - val_fbeta: 0.6110\nEpoch 3/20\n253/253 - 54s - loss: 0.2591 - fbeta: 0.5994 - val_loss: 0.2632 - val_fbeta: 0.6109\nEpoch 4/20\n253/253 - 54s - loss: 0.2436 - fbeta: 0.6084 - val_loss: 0.2967 - val_fbeta: 0.6061\n253/253 - 8s\n0.6777699392847032\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"40"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_1 = glob.glob('/kaggle/input/planets-dataset/planet/planet/test-jpg/*.jpg')\ntest_images_2 = glob.glob('/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional/*.jpg')","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=[]\nfor file in test_images_1:\n     X_test.append(cv2.resize(cv2.imread(file), (64,64)))\nfor file in test_images_2:\n     X_test.append(cv2.resize(cv2.imread(file), (64,64)))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(X_test, np.float16)/255","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(x_test, batch_size = 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_2 = model_2.predict(x_test, batch_size = 128)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tags1 = pd.DataFrame(prediction_2)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(tag_list)[x > 0.5]), axis=1)\n\n# converting the predictions of the first 40669 to a dataframe\nresult = pd.DataFrame({'image_name': test_classes['image_name'], 'tags': pred_tags1})","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('final_submission', index = False)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv('final_submission')","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"       Unnamed: 0 image_name                       tags\n0               0     test_0              primary clear\n1               1     test_1              primary clear\n2               2     test_2              primary clear\n3               3     test_3  primary agriculture clear\n4               4     test_4                    primary\n...           ...        ...                        ...\n61186       61186  file_9995              primary clear\n61187       61187  file_9996              primary clear\n61188       61188  file_9997              primary clear\n61189       61189  file_9998              primary clear\n61190       61190  file_9999              primary clear\n\n[61191 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>test_0</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>test_1</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>test_2</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>test_3</td>\n      <td>primary agriculture clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>test_4</td>\n      <td>primary</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61186</th>\n      <td>61186</td>\n      <td>file_9995</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>61187</th>\n      <td>61187</td>\n      <td>file_9996</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>61188</th>\n      <td>61188</td>\n      <td>file_9997</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>61189</th>\n      <td>61189</td>\n      <td>file_9998</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>61190</th>\n      <td>61190</td>\n      <td>file_9999</td>\n      <td>primary clear</td>\n    </tr>\n  </tbody>\n</table>\n<p>61191 rows × 3 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}